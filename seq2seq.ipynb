{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "import math\n",
    "def euDis(c1,c2):\n",
    "    return math.sqrt((c1[0]-c2[0])**2+(c1[1]-c2[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "HER_GRID = 20\n",
    "VER_GRID = 20\n",
    "HER_LEN = 1800\n",
    "VER_LEN = 1200\n",
    "a_col = 8\n",
    "a_row = 5\n",
    "hopDis = 3\n",
    "COL = HER_LEN//HER_GRID\n",
    "ROW = VER_LEN//VER_GRID\n",
    "def grid_anchors(rowCells,colCells,row=5,col=8):\n",
    "    st_w=colCells//(col+1)\n",
    "    st_h=rowCells//(row+1)\n",
    "    #print(st_w,st_h)\n",
    "    ini_w=0\n",
    "    ini_h=0\n",
    "    anchors = []\n",
    "    for i in range(row):\n",
    "        ini_h+=st_h\n",
    "        ini_w=0\n",
    "        for j in range(col):\n",
    "            ini_w+=st_w\n",
    "            anchors.append([ini_w,ini_h])\n",
    "    return anchors\n",
    "\n",
    "anchors = grid_anchors(ROW,COL)\n",
    "PRElOCATION=50\n",
    "hoplimits = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridPoint():\n",
    "    def __init__(self, pStr):\n",
    "        pStrList = pStr.split(\" \")\n",
    "        self.point = [int(x) for x in pStrList]\n",
    "        self.x = self.point[0]\n",
    "        self.y = self.point[1]\n",
    "        \n",
    "def encodeGPList(gpList, nRows):\n",
    "    x = np.zeros((nRows, COL+ROW))\n",
    "    #print(len(gpList))\n",
    "    for i, p in enumerate(gpList):\n",
    "        x[i, p.x] = 1\n",
    "        yy = COL+p.y\n",
    "        if(yy>=COL+ROW):\n",
    "            yy=COL+ROW-1\n",
    "        x[i, yy] = 1\n",
    "    return x\n",
    "                \n",
    "class constraint():\n",
    "    def __init__(self,consStr,gpList):\n",
    "        self.gpList = gpList\n",
    "        self.hopInfo=[]\n",
    "        if consStr == \"#\": \n",
    "            self.hopInfo = [1,0,0,0,0,0,0]\n",
    "        elif consStr == \"*\": \n",
    "            self.hopInfo = [0,1,0,0,0,0,0]\n",
    "        else:\n",
    "            cStrList = consStr.replace(\"(\",\"\").replace(\")\",\"\").split(\";\")[:5]\n",
    "            self.hopInfo = [0,0]+[int(float(x)) for x in cStrList]\n",
    "\n",
    "    def encodeConstraints(self,anchors,hopLimits):\n",
    "        col = max(len(anchors),hopLimits)\n",
    "        x = np.zeros((5, col))\n",
    "        for i, p in enumerate(self.hopInfo[2:]):\n",
    "            x[i, p] = 1\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def findFirstLastAppear(self):\n",
    "        leftAnchor = anchors[self.hopInfo[2]]\n",
    "        rightAnchor = anchors[self.hopInfo[3]]\n",
    "        circleCenter = anchors[self.hopInfo[4]]\n",
    "        x=circleCenter[0]\n",
    "        y=circleCenter[1]\n",
    "        r=self.hopInfo[6]*hopDis\n",
    "        a=self.hopInfo[5]*hopDis\n",
    "        a2=a-hopDis\n",
    "        \n",
    "        h1x=leftAnchor[0]\n",
    "        h1y=leftAnchor[1]\n",
    "        h2x=rightAnchor[0]\n",
    "        h2y=rightAnchor[1]\n",
    "\n",
    "        rr=r*r \n",
    "        res = [-1,-1]\n",
    "        for k,tup in enumerate(self.gpList):\n",
    "            i=tup.x\n",
    "            j=tup.y\n",
    "            di=x-i\n",
    "            dj=y-j\n",
    "            if  (di*di+dj*dj<=rr and euDis((i,j),(h1x,h1y))-euDis((i,j),(h2x,h2y))<=2*a and euDis((i,j),(h1x,h1y))-euDis((i,j),(h2x,h2y))>=2*a2):\n",
    "                res[0] = k\n",
    "                break\n",
    "        else: res[0] = k\n",
    "        for k,tup in enumerate(self.gpList[::-1]):\n",
    "            i=tup.x\n",
    "            j=tup.y\n",
    "            di=x-i\n",
    "            dj=y-j\n",
    "            if  (di*di+dj*dj<=rr and euDis((i,j),(h1x,h1y))-euDis((i,j),(h2x,h2y))<=2*a and euDis((i,j),(h1x,h1y))-euDis((i,j),(h2x,h2y))>=2*a2):\n",
    "                res[1] = len(self.gpList)  - k \n",
    "                break\n",
    "        else: res[1] = k \n",
    "        #print(res)\n",
    "        return res\n",
    "    \n",
    "    def myEncoderInput(self,nRows):\n",
    "        first,last = self.findFirstLastAppear()\n",
    "        gpList = []\n",
    "        \n",
    "        if last-first>=nRows:\n",
    "            gpList=self.gpList[first:first+nRows]\n",
    "        else:\n",
    "            if last-nRows>=0:\n",
    "                gpList=self.gpList[last-nRows:last]\n",
    "            else:\n",
    "                gpList = self.gpList[:min(len(self.gpList),nRows)]\n",
    "                \n",
    "        self.encoderInput = encodeGPList(gpList,nRows)\n",
    "        return self.encoderInput\n",
    "        \n",
    "    def decodeConstraint (self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "            \n",
    "        return [x for x in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "\n",
      "62 40\n",
      "\n",
      "61 40\n",
      "\n",
      "62 39\n",
      "\n",
      "61 39\n",
      "\n",
      "61 38\n",
      "\n",
      "60 39\n",
      "\n",
      "60 38\n",
      "\n",
      "59 39\n",
      "\n",
      "59 38\n",
      "\n",
      "58 38\n",
      "\n",
      "59 37\n",
      "\n",
      "58 37\n",
      "\n",
      "57 37\n",
      "\n",
      "58 36\n",
      "\n",
      "57 36\n",
      "\n",
      "56 37\n",
      "\n",
      "56 36\n",
      "\n",
      "55 36\n",
      "\n",
      "56 35\n",
      "\n",
      "55 35\n",
      "\n",
      "55 34\n",
      "\n",
      "54 35\n",
      "\n",
      "54 34\n",
      "\n",
      "53 35\n",
      "\n",
      "53 34\n",
      "\n",
      "52 34\n",
      "\n",
      "53 33\n",
      "\n",
      "52 33\n",
      "\n",
      "51 33\n",
      "\n",
      "52 32\n",
      "\n",
      "51 32\n",
      "\n",
      "51 31\n",
      "\n",
      "50 32\n",
      "\n",
      "50 31\n",
      "\n",
      "49 32\n",
      "\n",
      "49 31\n",
      "\n",
      "48 31\n",
      "\n",
      "49 30\n",
      "\n",
      "48 30\n",
      "\n",
      "47 30\n",
      "\n",
      "48 29\n",
      "\n",
      "47 29\n",
      "\n",
      "46 29\n",
      "\n",
      "45 29\n",
      "\n",
      "46 28\n",
      "\n",
      "45 28\n",
      "\n",
      "45 27\n",
      "\n",
      "44 28\n",
      "\n",
      "44 27\n",
      "\n",
      "43 28\n",
      "\n",
      "43 27\n",
      "\n",
      "42 27\n",
      "\n",
      "43 26\n",
      "\n",
      "42 26\n",
      "\n",
      "42 25\n",
      "\n",
      "41 26\n",
      "\n",
      "41 25\n",
      "\n",
      "40 26\n",
      "\n",
      "40 25\n",
      "\n",
      "39 25\n",
      "\n",
      "40 24\n",
      "\n",
      "38 25\n",
      "\n",
      "39 24\n",
      "\n",
      "40 23\n",
      "\n",
      "38 24\n",
      "\n",
      "39 23\n",
      "\n",
      "38 23\n",
      "\n",
      "38 22\n",
      "\n",
      "37 23\n",
      "\n",
      "37 22\n",
      "\n",
      "36 23\n",
      "\n",
      "36 22\n",
      "\n",
      "35 22\n",
      "\n",
      "34 22\n",
      "\n",
      "35 21\n",
      "\n",
      "34 21\n",
      "\n",
      "33 21\n",
      "\n",
      "32 21\n",
      "\n",
      "31 21\n",
      "\n",
      "32 22\n",
      "\n",
      "31 22\n",
      "\n",
      "31 23\n",
      "\n",
      "31 24\n",
      "\n",
      "32 23\n",
      "\n",
      "31 25\n",
      "\n",
      "32 24\n",
      "\n",
      "31 26\n",
      "\n",
      "32 25\n",
      "\n",
      "32 26\n",
      "\n",
      "32 27\n",
      "\n",
      "32 28\n",
      "\n",
      "32 29\n",
      "\n",
      "32 30\n",
      "\n",
      "31 29\n",
      "\n",
      "32 31\n",
      "\n",
      "31 30\n",
      "\n",
      "31 31\n",
      "\n",
      "30 30\n",
      "\n",
      "31 32\n",
      "\n",
      "30 31\n",
      "\n",
      "30 32\n",
      "\n",
      "30 33\n",
      "\n",
      "29 32\n",
      "\n",
      "30 34\n",
      "\n",
      "29 33\n",
      "\n",
      "29 34\n",
      "\n",
      "29 35\n",
      "\n",
      "29 36\n",
      "\n",
      "28 36\n",
      "\n",
      "29 37\n",
      "\n",
      "28 37\n",
      "\n",
      "28 38\n",
      "\n",
      "28 39\n",
      "\n",
      "27 38\n",
      "\n",
      "28 40\n",
      "\n",
      "27 39\n",
      "\n",
      "27 40\n",
      "\n",
      "(15; 36; 6; 3.000000; 10.000000; 3.000000; 3.000000)\n",
      "\n",
      "(7; 20; 24; 6.000000; 9.000000; 3.000000; 3.000000)\n",
      "\n",
      "(25; 11; 33; 4.000000; 11.000000; 3.000000; 3.000000)\n",
      "\n",
      "(33; 4; 34; 3.000000; 9.000000; 3.000000; 3.000000)\n",
      "\n",
      "(7; 31; 27; 3.000000; 8.000000; 3.000000; 3.000000)\n",
      "\n",
      "(39; 12; 3; 7.000000; 5.000000; 3.000000; 3.000000)\n",
      "\n",
      "(25; 12; 28; 4.000000; 3.000000; 3.000000; 3.000000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./dataExpect/50/preTrain_22\", \"r\")\n",
    "for t in f:\n",
    "    print(t)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62, 40], [61, 40], [62, 39], [61, 39], [61, 38], [60, 39], [60, 38], [59, 39], [59, 38], [58, 38], [59, 37], [58, 37], [57, 37], [58, 36], [57, 36], [56, 37], [56, 36], [55, 36], [56, 35], [55, 35], [55, 34], [54, 35], [54, 34], [53, 35], [53, 34], [52, 34], [53, 33], [52, 33], [51, 33], [52, 32], [51, 32], [51, 31], [50, 32], [50, 31], [49, 32], [49, 31], [48, 31], [49, 30], [48, 30], [47, 30], [48, 29], [47, 29], [46, 29], [45, 29], [46, 28], [45, 28], [45, 27], [44, 28], [44, 27], [43, 28], [43, 27], [42, 27], [43, 26], [42, 26], [42, 25], [41, 26], [41, 25], [40, 26], [40, 25], [39, 25], [40, 24], [38, 25], [39, 24], [40, 23], [38, 24], [39, 23], [38, 23], [38, 22], [37, 23], [37, 22], [36, 23], [36, 22], [35, 22], [34, 22], [35, 21], [34, 21], [33, 21], [32, 21], [31, 21], [32, 22], [31, 22], [31, 23], [31, 24], [32, 23], [31, 25], [32, 24], [31, 26], [32, 25], [32, 26], [32, 27], [32, 28], [32, 29], [32, 30], [31, 29], [32, 31], [31, 30], [31, 31], [30, 30], [31, 32], [30, 31], [30, 32], [30, 33], [29, 32], [30, 34], [29, 33], [29, 34], [29, 35], [29, 36], [28, 36], [29, 37], [28, 37], [28, 38], [28, 39], [27, 38], [28, 40], [27, 39], [27, 40]]\n",
      "[0, 0, 15, 36, 6, 3, 10]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./dataExpect/50/preTrain_22\", \"r\")\n",
    "TAS_SIZE = int(f.readline())\n",
    "gpList = []\n",
    "for i in range(TAS_SIZE):\n",
    "    gpList.append(GridPoint(f.readline()))\n",
    "print([p.point for p in gpList])\n",
    "firstConstraint = constraint(f.readline(),gpList)\n",
    "f.close()\n",
    "\n",
    "print(firstConstraint.hopInfo)\n",
    "decoderInput = firstConstraint.encodeConstraints(anchors,hoplimits)\n",
    "print(decoderInput)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoderInput = firstConstraint.myEncoderInput(PRElOCATION)\n",
    "print(encoderInput)\n",
    "print(encoderInput[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1417334\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "\n",
    "strokeRange = [20,194]\n",
    "totalNumOfTestCases = 0\n",
    "for sr in range(strokeRange[0],strokeRange[1]):\n",
    "    for item in range(1,100000):\n",
    "        fileName = \"./dataExpect/\"+str(sr)+\"/preTrain_\"+str(item)\n",
    "        if path.exists(fileName):\n",
    "            totalNumOfTestCases+=1\n",
    "print (totalNumOfTestCases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "\n",
    "\n",
    "x = np.zeros((totalNumOfTestCases, PRElOCATION, ROW+COL), dtype=np.bool)\n",
    "y = np.zeros((totalNumOfTestCases, 5, max(a_col*a_row,hoplimits)), dtype=np.bool)\n",
    "\n",
    "ttc=0\n",
    "for sr in range(strokeRange[0],strokeRange[1]):\n",
    "    for item in range(1,100000):\n",
    "        fileName = \"./dataExpect/\"+str(sr)+\"/preTrain_\"+str(item)\n",
    "        if path.exists(fileName):\n",
    "            f = open(fileName, \"r\")\n",
    "            TAS_SIZE = int(f.readline())\n",
    "            gpList = []\n",
    "            for i in range(TAS_SIZE):\n",
    "                gpList.append(GridPoint(f.readline()))\n",
    "            firstConstraint = constraint(f.readline(),gpList)\n",
    "            f.close()\n",
    "            y[ttc] = firstConstraint.encodeConstraints(anchors,hoplimits)\n",
    "            x[ttc] = firstConstraint.myEncoderInput(PRElOCATION)\n",
    "            ttc+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(1275601, 50, 150)\n",
      "(1275601, 5, 40)\n"
     ]
    }
   ],
   "source": [
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data:\n",
      "(141733, 50, 150)\n",
      "(141733, 5, 40)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 256\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7885889664343187364\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4372143343324139170\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16320562271449302993\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_38 (LSTM)               (None, 256)               416768    \n",
      "_________________________________________________________________\n",
      "repeat_vector_9 (RepeatVecto (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 5, 256)            525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 5, 40)             10280     \n",
      "=================================================================\n",
      "Total params: 952,360\n",
      "Trainable params: 952,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nencoder_inputs = Input(shape=(None, 50))\\nencoder = LSTM(256, return_state=True)\\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\\n# We discard `encoder_outputs` and only keep the states.\\nencoder_states = [state_h, state_c]\\n\\n# Set up the decoder, using `encoder_states` as initial state.\\ndecoder_inputs = Input(shape=(None, 5))\\n# We set up our decoder to return full output sequences,\\n# and to return internal states as well. We don't use the \\n# return states in the training model, but we will use them in inference.\\ndecoder_lstm = LSTM(5, return_sequences=True, return_state=True)\\ndecoder_outputs, _, _ = decoder_lstm(decoder_inputs,\\n                                     initial_state=encoder_states)\\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\\ndecoder_outputs = decoder_dense(decoder_outputs)\\n\\n# Define the model that will turn\\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\\n\\n\\n\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(PRElOCATION, ROW+COL)))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "\n",
    "model.add(layers.RepeatVector(5))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(40, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "'''\n",
    "\n",
    "encoder_inputs = Input(shape=(None, 50))\n",
    "encoder = LSTM(256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, 5))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(5, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ga(rowCells,colCells,row=5,col=8):\n",
    "    st_w=colCells//(col+1)\n",
    "    st_h=rowCells//(row+1)\n",
    "    #print(st_w,st_h)\n",
    "    ini_w=0\n",
    "    ini_h=0\n",
    "    anchors = {}\n",
    "    count = 0\n",
    "    for i in range(row):\n",
    "        ini_h+=st_h\n",
    "        ini_w=0\n",
    "        for j in range(col):\n",
    "            ini_w+=st_w\n",
    "            anchors[count] = (ini_w,ini_h)\n",
    "            count+=1\n",
    "    return anchors\n",
    "\n",
    "aac = ga(60,90)\n",
    "aac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "9966/9966 [==============================] - 1896s 190ms/step - loss: 0.6888 - accuracy: 0.7857 - val_loss: 0.6352 - val_accuracy: 0.8021\n",
      "T [7, 20, 24, 6, 11] \u001b[91m☒\u001b[0m [7, 20, 24, 6, 13]\n",
      "T [32, 19, 15, 6, 11] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 11]\n",
      "T [24, 4, 25, 3, 9] \u001b[91m☒\u001b[0m [39, 11, 34, 3, 5]\n",
      "T [32, 19, 15, 6, 9] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 9]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [7, 26, 12, 7, 6] \u001b[91m☒\u001b[0m [38, 35, 3, 3, 6]\n",
      "T [32, 19, 15, 6, 11] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 11]\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [8, 26, 11, 4, 4] \u001b[92m☑\u001b[0m [8, 26, 11, 4, 4]\n",
      "T [32, 19, 15, 6, 10] \u001b[91m☒\u001b[0m [32, 19, 15, 6, 11]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "9966/9966 [==============================] - 1894s 190ms/step - loss: 0.5947 - accuracy: 0.8126 - val_loss: 0.5799 - val_accuracy: 0.8166\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [23, 29, 27, 3, 4] \u001b[91m☒\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [15, 29, 12, 4, 4] \u001b[91m☒\u001b[0m [15, 26, 11, 4, 4]\n",
      "T [7, 20, 24, 6, 10] \u001b[91m☒\u001b[0m [7, 20, 24, 6, 13]\n",
      "T [7, 20, 24, 6, 12] \u001b[91m☒\u001b[0m [7, 20, 24, 6, 11]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "9966/9966 [==============================] - 1897s 190ms/step - loss: 0.5365 - accuracy: 0.8299 - val_loss: 0.5359 - val_accuracy: 0.8310\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [16, 26, 28, 3, 4] \u001b[91m☒\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [2, 5, 37, 3, 8] \u001b[92m☑\u001b[0m [2, 5, 37, 3, 8]\n",
      "T [0, 34, 36, 3, 7] \u001b[91m☒\u001b[0m [0, 34, 4, 6, 7]\n",
      "T [23, 27, 5, 6, 10] \u001b[91m☒\u001b[0m [37, 34, 2, 3, 8]\n",
      "T [7, 20, 24, 6, 11] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 11]\n",
      "T [23, 27, 26, 5, 5] \u001b[92m☑\u001b[0m [23, 27, 26, 5, 5]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "9966/9966 [==============================] - 1899s 191ms/step - loss: 0.4960 - accuracy: 0.8420 - val_loss: 0.5096 - val_accuracy: 0.8386\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [32, 19, 15, 6, 9] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 9]\n",
      "T [32, 19, 15, 6, 10] \u001b[91m☒\u001b[0m [32, 19, 15, 6, 9]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [24, 10, 36, 4, 7] \u001b[92m☑\u001b[0m [24, 10, 36, 4, 7]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [8, 26, 11, 4, 4] \u001b[92m☑\u001b[0m [8, 26, 11, 4, 4]\n",
      "T [32, 19, 15, 6, 9] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 9]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "9966/9966 [==============================] - 1919s 193ms/step - loss: 0.4649 - accuracy: 0.8513 - val_loss: 0.4922 - val_accuracy: 0.8441\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [16, 22, 21, 3, 4] \u001b[91m☒\u001b[0m [16, 22, 21, 4, 8]\n",
      "T [2, 5, 37, 3, 8] \u001b[92m☑\u001b[0m [2, 5, 37, 3, 8]\n",
      "T [22, 35, 26, 2, 5] \u001b[91m☒\u001b[0m [23, 35, 26, 2, 5]\n",
      "T [32, 19, 15, 6, 11] \u001b[91m☒\u001b[0m [32, 19, 15, 6, 12]\n",
      "T [30, 12, 27, 4, 4] \u001b[91m☒\u001b[0m [30, 11, 27, 4, 7]\n",
      "T [32, 5, 34, 6, 12] \u001b[91m☒\u001b[0m [32, 19, 15, 6, 12]\n",
      "T [7, 20, 24, 6, 13] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 13]\n",
      "T [25, 20, 32, 4, 13] \u001b[91m☒\u001b[0m [16, 22, 20, 2, 7]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "9966/9966 [==============================] - 1905s 191ms/step - loss: 0.4403 - accuracy: 0.8590 - val_loss: 0.4896 - val_accuracy: 0.8449\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [24, 34, 11, 3, 5] \u001b[92m☑\u001b[0m [24, 34, 11, 3, 5]\n",
      "T [37, 34, 2, 3, 8] \u001b[92m☑\u001b[0m [37, 34, 2, 3, 8]\n",
      "T [7, 20, 24, 6, 11] \u001b[91m☒\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [0, 3, 35, 3, 8] \u001b[91m☒\u001b[0m [0, 4, 36, 3, 8]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "9966/9966 [==============================] - 1913s 192ms/step - loss: 0.4202 - accuracy: 0.8651 - val_loss: 0.4715 - val_accuracy: 0.8518\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [3, 27, 35, 2, 7] \u001b[92m☑\u001b[0m [3, 27, 35, 2, 7]\n",
      "T [39, 36, 4, 3, 8] \u001b[91m☒\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [7, 20, 24, 6, 13] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 13]\n",
      "T [24, 11, 7, 6, 13] \u001b[92m☑\u001b[0m [24, 11, 7, 6, 13]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [7, 20, 24, 6, 12] \u001b[91m☒\u001b[0m [7, 20, 24, 6, 11]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "9966/9966 [==============================] - 1907s 191ms/step - loss: 0.4027 - accuracy: 0.8705 - val_loss: 0.4665 - val_accuracy: 0.8545\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [15, 26, 32, 8, 9] \u001b[92m☑\u001b[0m [15, 26, 32, 8, 9]\n",
      "T [23, 28, 5, 5, 9] \u001b[92m☑\u001b[0m [23, 28, 5, 5, 9]\n",
      "T [32, 19, 15, 6, 12] \u001b[91m☒\u001b[0m [32, 19, 15, 6, 13]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [32, 19, 15, 6, 11] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 11]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [14, 24, 18, 4, 1] \u001b[91m☒\u001b[0m [22, 24, 18, 4, 1]\n",
      "T [23, 28, 5, 5, 9] \u001b[91m☒\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "9966/9966 [==============================] - 1899s 191ms/step - loss: 0.3877 - accuracy: 0.8752 - val_loss: 0.4581 - val_accuracy: 0.8573\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [1, 35, 3, 3, 8] \u001b[91m☒\u001b[0m [2, 35, 37, 3, 8]\n",
      "T [32, 19, 15, 6, 10] \u001b[91m☒\u001b[0m [32, 19, 15, 6, 11]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [23, 2, 35, 7, 10] \u001b[91m☒\u001b[0m [38, 1, 35, 6, 10]\n",
      "T [7, 20, 24, 6, 11] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 11]\n",
      "T [32, 19, 15, 6, 11] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 11]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "9966/9966 [==============================] - 1901s 191ms/step - loss: 0.3741 - accuracy: 0.8795 - val_loss: 0.4570 - val_accuracy: 0.8581\n",
      "T [32, 19, 15, 6, 11] \u001b[91m☒\u001b[0m [32, 19, 15, 6, 12]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [37, 34, 2, 3, 8] \u001b[91m☒\u001b[0m [7, 27, 3, 2, 7]\n",
      "T [37, 34, 2, 3, 8] \u001b[92m☑\u001b[0m [37, 34, 2, 3, 8]\n",
      "T [24, 11, 7, 6, 12] \u001b[91m☒\u001b[0m [24, 11, 7, 6, 11]\n",
      "T [1, 4, 36, 3, 8] \u001b[91m☒\u001b[0m [1, 3, 35, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [0, 3, 35, 3, 8] \u001b[91m☒\u001b[0m [16, 3, 13, 4, 5]\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "9966/9966 [==============================] - 1891s 190ms/step - loss: 0.3617 - accuracy: 0.8834 - val_loss: 0.4517 - val_accuracy: 0.8602\n",
      "T [32, 19, 15, 6, 11] \u001b[91m☒\u001b[0m [32, 11, 15, 6, 11]\n",
      "T [33, 18, 11, 3, 4] \u001b[92m☑\u001b[0m [33, 18, 11, 3, 4]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [23, 11, 10, 5, 5] \u001b[92m☑\u001b[0m [23, 11, 10, 5, 5]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [8, 26, 11, 4, 4] \u001b[92m☑\u001b[0m [8, 26, 11, 4, 4]\n",
      "T [32, 19, 15, 6, 13] \u001b[91m☒\u001b[0m [32, 4, 36, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "9966/9966 [==============================] - 1871s 188ms/step - loss: 0.3512 - accuracy: 0.8867 - val_loss: 0.4483 - val_accuracy: 0.8627\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [16, 27, 2, 5, 9] \u001b[91m☒\u001b[0m [23, 27, 26, 2, 5]\n",
      "T [7, 20, 24, 6, 11] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 11]\n",
      "T [32, 19, 15, 6, 9] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 9]\n",
      "T [22, 26, 25, 5, 5] \u001b[91m☒\u001b[0m [37, 34, 25, 5, 5]\n",
      "T [2, 5, 37, 3, 8] \u001b[92m☑\u001b[0m [2, 5, 37, 3, 8]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [23, 11, 10, 5, 5] \u001b[92m☑\u001b[0m [23, 11, 10, 5, 5]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "9966/9966 [==============================] - 1897s 190ms/step - loss: 0.3413 - accuracy: 0.8898 - val_loss: 0.4475 - val_accuracy: 0.8631\n",
      "T [32, 19, 15, 6, 12] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 12]\n",
      "T [32, 19, 15, 6, 9] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 9]\n",
      "T [7, 20, 24, 6, 9] \u001b[91m☒\u001b[0m [15, 26, 32, 8, 9]\n",
      "T [24, 11, 7, 6, 12] \u001b[91m☒\u001b[0m [24, 11, 7, 6, 11]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [23, 28, 5, 5, 9] \u001b[92m☑\u001b[0m [23, 28, 5, 5, 9]\n",
      "T [36, 11, 19, 2, 1] \u001b[92m☑\u001b[0m [36, 11, 19, 2, 1]\n",
      "T [2, 18, 4, 3, 8] \u001b[92m☑\u001b[0m [2, 18, 4, 3, 8]\n",
      "T [25, 20, 24, 4, 12] \u001b[91m☒\u001b[0m [32, 4, 24, 4, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "9966/9966 [==============================] - 1899s 191ms/step - loss: 0.3325 - accuracy: 0.8925 - val_loss: 0.4469 - val_accuracy: 0.8636\n",
      "T [7, 20, 24, 6, 11] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 11]\n",
      "T [2, 5, 37, 3, 8] \u001b[92m☑\u001b[0m [2, 5, 37, 3, 8]\n",
      "T [31, 37, 12, 3, 5] \u001b[91m☒\u001b[0m [24, 37, 12, 3, 5]\n",
      "T [32, 19, 15, 6, 13] \u001b[91m☒\u001b[0m [8, 29, 39, 8, 9]\n",
      "T [37, 34, 2, 3, 8] \u001b[92m☑\u001b[0m [37, 34, 2, 3, 8]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [7, 20, 24, 6, 11] \u001b[91m☒\u001b[0m [7, 20, 24, 6, 13]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "9966/9966 [==============================] - 1906s 191ms/step - loss: 0.3244 - accuracy: 0.8952 - val_loss: 0.4498 - val_accuracy: 0.8642\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [16, 11, 34, 5, 9] \u001b[91m☒\u001b[0m [16, 11, 34, 3, 9]\n",
      "T [7, 20, 24, 6, 12] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 12]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "9966/9966 [==============================] - 1924s 193ms/step - loss: 0.3164 - accuracy: 0.8976 - val_loss: 0.4489 - val_accuracy: 0.8656\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [0, 27, 36, 7, 5] \u001b[91m☒\u001b[0m [0, 27, 36, 3, 8]\n",
      "T [8, 29, 39, 8, 9] \u001b[91m☒\u001b[0m [24, 29, 39, 8, 9]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [32, 4, 34, 4, 10] \u001b[91m☒\u001b[0m [15, 36, 6, 4, 10]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [7, 20, 24, 6, 13] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 13]\n",
      "T [39, 13, 35, 5, 8] \u001b[91m☒\u001b[0m [1, 4, 36, 4, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "9966/9966 [==============================] - 1930s 194ms/step - loss: 0.3093 - accuracy: 0.8998 - val_loss: 0.4536 - val_accuracy: 0.8641\n",
      "T [24, 11, 7, 6, 13] \u001b[92m☑\u001b[0m [24, 11, 7, 6, 13]\n",
      "T [25, 36, 12, 4, 5] \u001b[92m☑\u001b[0m [25, 36, 12, 4, 5]\n",
      "T [1, 4, 36, 3, 8] \u001b[91m☒\u001b[0m [1, 4, 27, 3, 4]\n",
      "T [23, 36, 12, 4, 5] \u001b[91m☒\u001b[0m [2, 10, 4, 2, 5]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [32, 19, 15, 6, 9] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 9]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [6, 36, 11, 3, 4] \u001b[91m☒\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "9966/9966 [==============================] - 1916s 192ms/step - loss: 0.3027 - accuracy: 0.9020 - val_loss: 0.4491 - val_accuracy: 0.8663\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [2, 5, 37, 3, 8] \u001b[92m☑\u001b[0m [2, 5, 37, 3, 8]\n",
      "T [31, 26, 7, 7, 17] \u001b[91m☒\u001b[0m [37, 34, 36, 3, 4]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [23, 11, 10, 5, 5] \u001b[91m☒\u001b[0m [4, 17, 19, 2, 1]\n",
      "T [39, 36, 4, 3, 8] \u001b[91m☒\u001b[0m [39, 3, 35, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [16, 27, 2, 5, 9] \u001b[92m☑\u001b[0m [16, 27, 2, 5, 9]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "9966/9966 [==============================] - 1918s 192ms/step - loss: 0.2965 - accuracy: 0.9041 - val_loss: 0.4561 - val_accuracy: 0.8657\n",
      "T [32, 19, 15, 6, 11] \u001b[91m☒\u001b[0m [32, 11, 7, 6, 11]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [31, 3, 28, 4, 8] \u001b[92m☑\u001b[0m [31, 3, 28, 4, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [16, 30, 20, 4, 1] \u001b[91m☒\u001b[0m [16, 14, 20, 4, 5]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [32, 19, 15, 6, 9] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 9]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [6, 28, 2, 5, 8] \u001b[91m☒\u001b[0m [6, 12, 2, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "9966/9966 [==============================] - 1920s 193ms/step - loss: 0.2909 - accuracy: 0.9057 - val_loss: 0.4570 - val_accuracy: 0.8652\n",
      "T [7, 20, 24, 6, 13] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 13]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [32, 19, 15, 6, 11] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 11]\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [7, 28, 35, 7, 5] \u001b[91m☒\u001b[0m [7, 20, 35, 7, 5]\n",
      "T [23, 5, 2, 2, 8] \u001b[92m☑\u001b[0m [23, 5, 2, 2, 8]\n",
      "T [33, 5, 13, 2, 6] \u001b[92m☑\u001b[0m [33, 5, 13, 2, 6]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "9966/9966 [==============================] - 1924s 193ms/step - loss: 0.2851 - accuracy: 0.9073 - val_loss: 0.4604 - val_accuracy: 0.8661\n",
      "T [7, 20, 24, 6, 12] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 12]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [23, 11, 10, 5, 5] \u001b[92m☑\u001b[0m [23, 11, 10, 5, 5]\n",
      "T [22, 11, 36, 5, 9] \u001b[91m☒\u001b[0m [32, 11, 36, 5, 9]\n",
      "T [3, 27, 35, 2, 7] \u001b[92m☑\u001b[0m [3, 27, 35, 2, 7]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [32, 19, 15, 6, 12] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 12]\n",
      "T [32, 19, 15, 6, 9] \u001b[91m☒\u001b[0m [2, 5, 37, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "9966/9966 [==============================] - 1928s 193ms/step - loss: 0.2804 - accuracy: 0.9090 - val_loss: 0.4606 - val_accuracy: 0.8673\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [39, 13, 35, 5, 8] \u001b[92m☑\u001b[0m [39, 13, 35, 5, 8]\n",
      "T [23, 27, 26, 5, 5] \u001b[91m☒\u001b[0m [23, 27, 26, 2, 5]\n",
      "T [25, 35, 12, 3, 5] \u001b[91m☒\u001b[0m [25, 35, 12, 6, 5]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[91m☒\u001b[0m [1, 4, 20, 2, 1]\n",
      "T [5, 29, 4, 3, 8] \u001b[91m☒\u001b[0m [39, 14, 12, 4, 5]\n",
      "T [7, 20, 24, 6, 12] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 12]\n",
      "T [16, 12, 13, 5, 5] \u001b[92m☑\u001b[0m [16, 12, 13, 5, 5]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "9966/9966 [==============================] - 1928s 193ms/step - loss: 0.2756 - accuracy: 0.9105 - val_loss: 0.4671 - val_accuracy: 0.8654\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [32, 11, 12, 5, 4] \u001b[91m☒\u001b[0m [37, 28, 12, 4, 4]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [37, 12, 20, 2, 1] \u001b[92m☑\u001b[0m [37, 12, 20, 2, 1]\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [8, 31, 4, 12, 16] \u001b[91m☒\u001b[0m [32, 19, 15, 6, 13]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "9966/9966 [==============================] - 1925s 193ms/step - loss: 0.2712 - accuracy: 0.9120 - val_loss: 0.4649 - val_accuracy: 0.8662\n",
      "T [8, 34, 36, 2, 7] \u001b[92m☑\u001b[0m [8, 34, 36, 2, 7]\n",
      "T [37, 34, 2, 3, 8] \u001b[92m☑\u001b[0m [37, 34, 2, 3, 8]\n",
      "T [32, 12, 33, 5, 10] \u001b[91m☒\u001b[0m [15, 5, 9, 2, 9]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [7, 20, 24, 6, 13] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 13]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [23, 4, 11, 2, 5] \u001b[91m☒\u001b[0m [24, 35, 11, 4, 5]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [7, 18, 24, 8, 9] \u001b[91m☒\u001b[0m [39, 18, 24, 8, 9]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "9966/9966 [==============================] - 1892s 190ms/step - loss: 0.2667 - accuracy: 0.9132 - val_loss: 0.4665 - val_accuracy: 0.8660\n",
      "T [32, 19, 15, 6, 9] \u001b[91m☒\u001b[0m [32, 19, 37, 6, 8]\n",
      "T [32, 19, 15, 6, 13] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 13]\n",
      "T [8, 29, 39, 8, 9] \u001b[92m☑\u001b[0m [8, 29, 39, 8, 9]\n",
      "T [24, 11, 7, 6, 10] \u001b[91m☒\u001b[0m [24, 11, 7, 6, 12]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "9966/9966 [==============================] - 1886s 189ms/step - loss: 0.2627 - accuracy: 0.9147 - val_loss: 0.4716 - val_accuracy: 0.8659\n",
      "T [1, 4, 36, 3, 8] \u001b[91m☒\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[91m☒\u001b[0m [38, 35, 3, 5, 8]\n",
      "T [32, 19, 15, 6, 9] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 9]\n",
      "T [8, 34, 36, 2, 7] \u001b[92m☑\u001b[0m [8, 34, 36, 2, 7]\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [24, 34, 28, 2, 4] \u001b[91m☒\u001b[0m [22, 27, 4, 3, 9]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "9966/9966 [==============================] - 1889s 189ms/step - loss: 0.2593 - accuracy: 0.9158 - val_loss: 0.4761 - val_accuracy: 0.8663\n",
      "T [38, 35, 3, 3, 8] \u001b[91m☒\u001b[0m [39, 35, 3, 3, 8]\n",
      "T [38, 35, 3, 3, 8] \u001b[91m☒\u001b[0m [14, 35, 4, 3, 8]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [32, 19, 15, 6, 13] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 13]\n",
      "T [23, 29, 27, 3, 4] \u001b[91m☒\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [32, 19, 15, 6, 12] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 12]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [7, 20, 24, 6, 11] \u001b[91m☒\u001b[0m [7, 27, 4, 5, 9]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "9966/9966 [==============================] - 1888s 189ms/step - loss: 0.2556 - accuracy: 0.9169 - val_loss: 0.4769 - val_accuracy: 0.8662\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [2, 5, 37, 3, 8] \u001b[91m☒\u001b[0m [8, 29, 39, 8, 9]\n",
      "T [7, 20, 24, 6, 9] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 9]\n",
      "T [14, 3, 27, 4, 5] \u001b[91m☒\u001b[0m [31, 2, 27, 6, 5]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [32, 11, 36, 6, 7] \u001b[91m☒\u001b[0m [24, 11, 36, 6, 7]\n",
      "T [15, 26, 32, 8, 9] \u001b[92m☑\u001b[0m [15, 26, 32, 8, 9]\n",
      "T [32, 19, 15, 6, 9] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 9]\n",
      "T [23, 28, 5, 5, 9] \u001b[91m☒\u001b[0m [6, 28, 5, 3, 9]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "9966/9966 [==============================] - 1887s 189ms/step - loss: 0.2522 - accuracy: 0.9180 - val_loss: 0.4795 - val_accuracy: 0.8666\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [7, 20, 24, 6, 12] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 12]\n",
      "T [15, 28, 32, 6, 10] \u001b[91m☒\u001b[0m [7, 20, 24, 6, 11]\n",
      "T [0, 3, 35, 3, 8] \u001b[91m☒\u001b[0m [23, 18, 17, 8, 5]\n",
      "T [39, 36, 4, 3, 8] \u001b[92m☑\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [7, 20, 24, 6, 9] \u001b[91m☒\u001b[0m [33, 26, 35, 3, 8]\n",
      "T [38, 12, 11, 3, 5] \u001b[91m☒\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [36, 11, 19, 2, 1] \u001b[92m☑\u001b[0m [36, 11, 19, 2, 1]\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "9966/9966 [==============================] - 1890s 190ms/step - loss: 0.2492 - accuracy: 0.9190 - val_loss: 0.4798 - val_accuracy: 0.8676\n",
      "T [32, 19, 15, 6, 10] \u001b[92m☑\u001b[0m [32, 19, 15, 6, 10]\n",
      "T [8, 26, 11, 4, 4] \u001b[92m☑\u001b[0m [8, 26, 11, 4, 4]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [9, 35, 36, 2, 6] \u001b[91m☒\u001b[0m [17, 27, 35, 3, 8]\n",
      "T [0, 3, 35, 3, 8] \u001b[92m☑\u001b[0m [0, 3, 35, 3, 8]\n",
      "T [7, 20, 24, 6, 12] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 12]\n"
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "    \n",
    "    \n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        correct = firstConstraint.decodeConstraint(rowy[0])\n",
    "        guess = firstConstraint.decodeConstraint(preds[0], calc_argmax=False)\n",
    "        \n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n",
      "T [1, 4, 36, 3, 8] \u001b[92m☑\u001b[0m [1, 4, 36, 3, 8]\n",
      "T [2, 29, 38, 7, 5] \u001b[91m☒\u001b[0m [32, 19, 15, 6, 16]\n",
      "T [32, 19, 15, 6, 10] \u001b[91m☒\u001b[0m [32, 19, 15, 6, 12]\n",
      "T [38, 35, 3, 3, 8] \u001b[92m☑\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [23, 18, 19, 2, 4] \u001b[91m☒\u001b[0m [32, 21, 15, 8, 8]\n",
      "T [23, 11, 10, 5, 5] \u001b[91m☒\u001b[0m [39, 36, 4, 3, 8]\n",
      "T [0, 3, 35, 3, 8] \u001b[91m☒\u001b[0m [38, 35, 3, 3, 8]\n",
      "T [7, 20, 24, 6, 10] \u001b[92m☑\u001b[0m [7, 20, 24, 6, 10]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        correct = firstConstraint.decodeConstraint(rowy[0])\n",
    "        guess = firstConstraint.decodeConstraint(preds[0], calc_argmax=False)\n",
    "        \n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
